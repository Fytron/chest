{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a81a6175",
   "metadata": {},
   "source": [
    "# Decision Tree Implementation  \n",
    "\n",
    "This notebook demonstrates an implementation of a **Decision Tree induction algorithm** for classification tasks. The project is designed to showcase the functionality of decision trees while accommodating both real-valued and nominal features.\n",
    "\n",
    "---\n",
    "\n",
    "## Key Features:\n",
    "1. **Decision Tree Algorithm**:  \n",
    "   - Implements a decision tree induction algorithm for classification.  \n",
    "   - Handles both real-valued and nominal features.  \n",
    "   - Does not handle missing values or regression tasks (real-valued target features).  \n",
    "\n",
    "2. **Split Criterion**:  \n",
    "   - Users can choose between **information entropy** or **Gini impurity** as the criterion for determining the best split.\n",
    "\n",
    "3. **Binary Splits for Real-Valued Features**:  \n",
    "   - Splits are calculated using the following rule:  \n",
    "     An instance with a feature value lower than the mean feature value follows the left edge from the split node, while all other instances follow the right edge.  \n",
    "\n",
    "4. **Dataset Demonstration**:  \n",
    "   - The algorithm is tested on three datasets:  \n",
    "     - **Iris dataset**  \n",
    "     - **Wine dataset**  \n",
    "     - **Adult dataset** from the **UCI Machine Learning Repository**, formatted appropriately for this implementation.\n",
    "\n",
    "---\n",
    "\n",
    "## Mathematical Concepts:\n",
    "\n",
    "### 1. Entropy Formula:\n",
    "The entropy measures the amount of impurity or uncertainty in the dataset and is defined as:\n",
    "\n",
    "$ H(T) = - \\sum_{i=1}^{n} p_i \\log_2(p_i) $\n",
    "\n",
    "Where:\n",
    "- $p_i$ is the probability of each class in the dataset.  \n",
    "\n",
    "### 2. Information Gain:\n",
    "Information gain measures the reduction in entropy after a dataset is split based on a feature. It is calculated as:\n",
    "\n",
    "$ IG(T, X) = H(T) - \\sum_{i=1}^{k} \\frac{|T_i|}{|T|} H(T_i) $\n",
    "\n",
    "Where:\n",
    "- $H(T)$ is the entropy of the original dataset $T$.  \n",
    "- $T_i$ represents the subsets of $T$ resulting from a split on feature $X$.  \n",
    "- $|T_i|$ and $|T|$ denote the number of examples in subset $T_i$ and the original dataset $T$, respectively.\n",
    "\n",
    "### 3. Probability:\n",
    "The probability $p_i$ used in entropy is calculated as:\n",
    "\n",
    "$ p_i = \\frac{\\text{Number of instances in class } i}{\\text{Total instances in the dataset}} $\n",
    "\n",
    "This represents the proportion of examples belonging to each class in the dataset.\n",
    "\n",
    "---\n",
    "\n",
    "### Example Usage:\n",
    "This implementation demonstrates the construction of decision trees and evaluates their performance on common classification datasets. For real-valued features, binary splits are applied using the mean value rule described above.\n",
    "\n",
    "---\n",
    "\n",
    "### References:\n",
    "For more information on decision trees and related calculations, refer to the [Wikipedia article on Information Gain](https://en.wikipedia.org/wiki/Information_gain_(decision_tree)).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "76918890",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "class DecisionTree:\n",
    "    # Helper class to create our nodes in the decision tree\n",
    "    class Node:\n",
    "        def __init__(self, feature=None, threshold=None, left=None, right=None, *, value=None):\n",
    "            self.feature = feature\n",
    "            self.threshold = threshold\n",
    "            self.left = left\n",
    "            self.right = right\n",
    "            self.value = value\n",
    "\n",
    "        def is_leaf_node(self):\n",
    "            return self.value is not None\n",
    "    \n",
    "    def __init__(self, min_samples_split=2, max_depth=100, n_feats=None):\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.max_depth = max_depth\n",
    "        self.n_feats = n_feats\n",
    "        self.root = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.n_feats = X.shape[1] if not self.n_feats else min(self.n_feats, X.shape[1])\n",
    "        self.root = self._grow_tree(X, y)\n",
    "\n",
    "    def _grow_tree(self, X, y, depth=0):\n",
    "        n_labels = len(np.unique(y))\n",
    "        n_samples, n_features = X.shape\n",
    "\n",
    "        # Stopping criteria\n",
    "        if (\n",
    "            depth >= self.max_depth\n",
    "            or n_labels == 1\n",
    "            or n_samples < self.min_samples_split\n",
    "        ):\n",
    "            leaf_value = self._most_common_label(y)\n",
    "            return Node(value=leaf_value)\n",
    "\n",
    "        feat_idxs = np.random.choice(n_features, self.n_feats, replace=False)\n",
    "\n",
    "        # Determine the best splitting criteria by calculating the\n",
    "        # information gain through entropy.\n",
    "        best_feat, best_thresh = self._best_criteria(X, y, feat_idxs)\n",
    "\n",
    "        # Recursively run _grow_tree on the children as well\n",
    "        left_idxs, right_idxs = self._split(X[:, best_feat], best_thresh)\n",
    "        left = self._grow_tree(X[left_idxs, :], y[left_idxs], depth + 1)\n",
    "        right = self._grow_tree(X[right_idxs, :], y[right_idxs], depth + 1)\n",
    "        \n",
    "        return Node(best_feat, best_thresh, left, right)\n",
    "\n",
    "    def _best_criteria(self, X, y, feat_idxs):\n",
    "        split_idx, split_thresh = None, None\n",
    "        best_gain = 0\n",
    "        \n",
    "        for feat_idx in feat_idxs:\n",
    "            X_column = X[:, feat_idx]\n",
    "\n",
    "            # An instance with a feature value lower than the mean feature value \n",
    "            # follows the left edge from the split node while all other instances follow\n",
    "            # the right edge from the split node. To do this, we first check whether the\n",
    "            # feature column contains only numbers. If it does, we calculate the mean\n",
    "            # and set it as the splitting threshold. The other case is that\n",
    "            # the feature contains some nominal values and we can only separate them\n",
    "            # by taking their unique values as thresholds.\n",
    "            if np.issubdtype(X_column.dtype, np.number):\n",
    "                thresholds = np.mean(X_column)\n",
    "            else:\n",
    "                thresholds = np.unique(X_column)            \n",
    "            \n",
    "            # Calculate the information gain for each threshold\n",
    "            for threshold in thresholds:\n",
    "                gain = self._information_gain(y, X_column, threshold)\n",
    "\n",
    "                if gain > best_gain:\n",
    "                    best_gain = gain\n",
    "                    split_idx = feat_idx\n",
    "                    split_thresh = threshold\n",
    "\n",
    "        return split_idx, split_thresh\n",
    "\n",
    "    def _information_gain(self, y, X_column, split_thresh):\n",
    "        # parent loss\n",
    "        parent_entropy = entropy(y)\n",
    "\n",
    "        # generate split\n",
    "        left_idxs, right_idxs = self._split(X_column, split_thresh)\n",
    "\n",
    "        if len(left_idxs) == 0 or len(right_idxs) == 0:\n",
    "            return 0\n",
    "\n",
    "        # compute the weighted avg. of the loss for the children\n",
    "        n = len(y)\n",
    "        n_left, n_right = len(left_idxs), len(right_idxs)\n",
    "        e_left, e_right = entropy(y[left_idxs]), entropy(y[right_idxs])\n",
    "        child_entropy = (n_left / n) * e_left + (n_right / n) * e_right\n",
    "\n",
    "        # The information gained is the difference in loss before and after split\n",
    "        info_gain = parent_entropy - child_entropy\n",
    "        return info_gain\n",
    "\n",
    "    def _split(self, X_column, split_thresh):\n",
    "        left_idxs = np.argwhere(X_column <= split_thresh).flatten()\n",
    "#         print(X_column[left_idxs],X_column[left_idxs])\n",
    "        right_idxs = np.argwhere(X_column > split_thresh).flatten()\n",
    "        return left_idxs, right_idxs\n",
    "\n",
    "    def _traverse_tree(self, x, node):\n",
    "        if node.is_leaf_node():\n",
    "            return node.value\n",
    "\n",
    "        if x[node.feature] <= node.threshold:\n",
    "            return self._traverse_tree(x, node.left)\n",
    "        return self._traverse_tree(x, node.right)\n",
    "\n",
    "    def _most_common_label(self, y):\n",
    "        counter = Counter(y)\n",
    "        most_common = counter.most_common(1)[0][0]\n",
    "        return most_common\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return np.array([self._traverse_tree(x, self.root) for x in X])\n",
    "    \n",
    "def entropy(y):\n",
    "    hist = np.bincount(y)\n",
    "    ps = hist / len(y)\n",
    "    return -np.sum([p * np.log2(p) for p in ps if p > 0])\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "    accuracy = np.sum(y_true == y_pred) / len(y_true)\n",
    "    return accuracy\n",
    "\n",
    "def train_test_split(X, y, test_size=0.2, random_state=None):\n",
    "    np.random.seed(random_state)\n",
    "    shuffle_index = np.random.permutation(len(X))\n",
    "    test_index = int(len(X) * test_size)\n",
    "    X_train = X[shuffle_index[test_index:]]\n",
    "    y_train = y[shuffle_index[test_index:]]\n",
    "    X_test = X[shuffle_index[:test_index]]\n",
    "    y_test = y[shuffle_index[:test_index]]\n",
    "    return X_train, X_test, y_train, y_test "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55842125",
   "metadata": {},
   "source": [
    "## Iris Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2ea84754",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length</th>\n",
       "      <th>sepal width</th>\n",
       "      <th>petal length</th>\n",
       "      <th>petal width</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    sepal length sepal width petal length petal width           class\n",
       "1            5.1         3.5          1.4         0.2     Iris-setosa\n",
       "2            4.9         3.0          1.4         0.2     Iris-setosa\n",
       "3            4.7         3.2          1.3         0.2     Iris-setosa\n",
       "4            4.6         3.1          1.5         0.2     Iris-setosa\n",
       "5            5.0         3.6          1.4         0.2     Iris-setosa\n",
       "..           ...         ...          ...         ...             ...\n",
       "146          6.7         3.0          5.2         2.3  Iris-virginica\n",
       "147          6.3         2.5          5.0         1.9  Iris-virginica\n",
       "148          6.5         3.0          5.2         2.0  Iris-virginica\n",
       "149          6.2         3.4          5.4         2.3  Iris-virginica\n",
       "150          5.9         3.0          5.1         1.8  Iris-virginica\n",
       "\n",
       "[150 rows x 5 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = 'iris.tmls'\n",
    "data = pd.read_csv(filename)\n",
    "# Remove the line with \"r,r,r,r,n\"\n",
    "data = data.drop(data.index[0])\n",
    "\n",
    "y_data = data['class']\n",
    "# Replace class names\n",
    "for i, value in enumerate(np.unique(y_data)):\n",
    "    y_data = np.where(y_data == value, i, y_data)\n",
    "y_data = np.asarray(y_data)\n",
    "y_data = y_data.astype(dtype=np.int64)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8b3dafdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iris Dataset - Multiple runs:\n",
      "\n",
      "Accuracy: 0.8666666666666667\n",
      "Accuracy: 0.9333333333333333\n",
      "Accuracy: 0.9\n",
      "Accuracy: 1.0\n",
      "Accuracy: 0.9\n"
     ]
    }
   ],
   "source": [
    "print(\"Iris Dataset - Multiple runs:\\n\")\n",
    "for i in range(5):\n",
    "    x_data = data.iloc[:, :-1].values\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        x_data, y_data, test_size=0.2, random_state=None\n",
    "    )\n",
    "\n",
    "    dt = DecisionTree(max_depth=10)\n",
    "    dt.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = dt.predict(X_test)\n",
    "\n",
    "    acc = accuracy(y_test, y_pred)\n",
    "\n",
    "    print(\"Accuracy:\", acc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "146e92d2",
   "metadata": {},
   "source": [
    "## Wine Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4498d8ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alcohol</th>\n",
       "      <th>malic acid</th>\n",
       "      <th>ash</th>\n",
       "      <th>alcalinity of ash</th>\n",
       "      <th>magnesium</th>\n",
       "      <th>total phenols</th>\n",
       "      <th>flavanoids</th>\n",
       "      <th>nonflavanoid phenols</th>\n",
       "      <th>proanthocyanins</th>\n",
       "      <th>color intensity</th>\n",
       "      <th>hue</th>\n",
       "      <th>OD280/OD315 of diluted wines</th>\n",
       "      <th>proline</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127</td>\n",
       "      <td>2.8</td>\n",
       "      <td>3.06</td>\n",
       "      <td>.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.2</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1050</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101</td>\n",
       "      <td>2.8</td>\n",
       "      <td>3.24</td>\n",
       "      <td>.3</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.5</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.8</td>\n",
       "      <td>.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21</td>\n",
       "      <td>118</td>\n",
       "      <td>2.8</td>\n",
       "      <td>2.69</td>\n",
       "      <td>.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>13.71</td>\n",
       "      <td>5.65</td>\n",
       "      <td>2.45</td>\n",
       "      <td>20.5</td>\n",
       "      <td>95</td>\n",
       "      <td>1.68</td>\n",
       "      <td>.61</td>\n",
       "      <td>.52</td>\n",
       "      <td>1.06</td>\n",
       "      <td>7.7</td>\n",
       "      <td>.64</td>\n",
       "      <td>1.74</td>\n",
       "      <td>740</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>13.4</td>\n",
       "      <td>3.91</td>\n",
       "      <td>2.48</td>\n",
       "      <td>23</td>\n",
       "      <td>102</td>\n",
       "      <td>1.8</td>\n",
       "      <td>.75</td>\n",
       "      <td>.43</td>\n",
       "      <td>1.41</td>\n",
       "      <td>7.3</td>\n",
       "      <td>.7</td>\n",
       "      <td>1.56</td>\n",
       "      <td>750</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>13.27</td>\n",
       "      <td>4.28</td>\n",
       "      <td>2.26</td>\n",
       "      <td>20</td>\n",
       "      <td>120</td>\n",
       "      <td>1.59</td>\n",
       "      <td>.69</td>\n",
       "      <td>.43</td>\n",
       "      <td>1.35</td>\n",
       "      <td>10.2</td>\n",
       "      <td>.59</td>\n",
       "      <td>1.56</td>\n",
       "      <td>835</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>13.17</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.37</td>\n",
       "      <td>20</td>\n",
       "      <td>120</td>\n",
       "      <td>1.65</td>\n",
       "      <td>.68</td>\n",
       "      <td>.53</td>\n",
       "      <td>1.46</td>\n",
       "      <td>9.3</td>\n",
       "      <td>.6</td>\n",
       "      <td>1.62</td>\n",
       "      <td>840</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>14.13</td>\n",
       "      <td>4.1</td>\n",
       "      <td>2.74</td>\n",
       "      <td>24.5</td>\n",
       "      <td>96</td>\n",
       "      <td>2.05</td>\n",
       "      <td>.76</td>\n",
       "      <td>.56</td>\n",
       "      <td>1.35</td>\n",
       "      <td>9.2</td>\n",
       "      <td>.61</td>\n",
       "      <td>1.6</td>\n",
       "      <td>560</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>178 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    alcohol malic acid   ash alcalinity of ash magnesium total phenols  \\\n",
       "1     14.23       1.71  2.43              15.6       127           2.8   \n",
       "2      13.2       1.78  2.14              11.2       100          2.65   \n",
       "3     13.16       2.36  2.67              18.6       101           2.8   \n",
       "4     14.37       1.95   2.5              16.8       113          3.85   \n",
       "5     13.24       2.59  2.87                21       118           2.8   \n",
       "..      ...        ...   ...               ...       ...           ...   \n",
       "174   13.71       5.65  2.45              20.5        95          1.68   \n",
       "175    13.4       3.91  2.48                23       102           1.8   \n",
       "176   13.27       4.28  2.26                20       120          1.59   \n",
       "177   13.17       2.59  2.37                20       120          1.65   \n",
       "178   14.13        4.1  2.74              24.5        96          2.05   \n",
       "\n",
       "    flavanoids nonflavanoid phenols proanthocyanins color intensity   hue  \\\n",
       "1         3.06                  .28            2.29            5.64  1.04   \n",
       "2         2.76                  .26            1.28            4.38  1.05   \n",
       "3         3.24                   .3            2.81            5.68  1.03   \n",
       "4         3.49                  .24            2.18             7.8   .86   \n",
       "5         2.69                  .39            1.82            4.32  1.04   \n",
       "..         ...                  ...             ...             ...   ...   \n",
       "174        .61                  .52            1.06             7.7   .64   \n",
       "175        .75                  .43            1.41             7.3    .7   \n",
       "176        .69                  .43            1.35            10.2   .59   \n",
       "177        .68                  .53            1.46             9.3    .6   \n",
       "178        .76                  .56            1.35             9.2   .61   \n",
       "\n",
       "    OD280/OD315 of diluted wines proline class  \n",
       "1                           3.92    1065     1  \n",
       "2                            3.4    1050     1  \n",
       "3                           3.17    1185     1  \n",
       "4                           3.45    1480     1  \n",
       "5                           2.93     735     1  \n",
       "..                           ...     ...   ...  \n",
       "174                         1.74     740     3  \n",
       "175                         1.56     750     3  \n",
       "176                         1.56     835     3  \n",
       "177                         1.62     840     3  \n",
       "178                          1.6     560     3  \n",
       "\n",
       "[178 rows x 14 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = 'wine.tmls'\n",
    "data = pd.read_csv(filename)\n",
    "# Remove the line with \"r,r,r,r,r,r,r,r,r,r,r,r,r,r\"\n",
    "data = data.drop(data.index[0])\n",
    "\n",
    "y_data = data['class']\n",
    "# Replace class names\n",
    "for i, value in enumerate(np.unique(y_data)):\n",
    "    y_data = np.where(y_data == value, i, y_data)\n",
    "y_data = np.asarray(y_data)\n",
    "y_data = y_data.astype(dtype=np.int64)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ed93ac0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wine Dataset - Multiple runs:\n",
      "\n",
      "Accuracy: 0.8285714285714286\n",
      "Accuracy: 0.8285714285714286\n",
      "Accuracy: 0.8571428571428571\n",
      "Accuracy: 0.8571428571428571\n",
      "Accuracy: 0.8857142857142857\n"
     ]
    }
   ],
   "source": [
    "print(\"Wine Dataset - Multiple runs:\\n\")\n",
    "for i in range(5):\n",
    "    x_data = data.iloc[:, :-1].values\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        x_data, y_data, test_size=0.2, random_state=None\n",
    "    )\n",
    "\n",
    "    dt = DecisionTree(max_depth=10)\n",
    "    dt.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = dt.predict(X_test)\n",
    "\n",
    "    acc = accuracy(y_test, y_pred)\n",
    "\n",
    "    print(\"Accuracy:\", acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "843a371e",
   "metadata": {},
   "source": [
    "## Adult Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "091e21b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32557</th>\n",
       "      <td>27</td>\n",
       "      <td>Private</td>\n",
       "      <td>257302</td>\n",
       "      <td>Assoc-acdm</td>\n",
       "      <td>12</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Tech-support</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32558</th>\n",
       "      <td>40</td>\n",
       "      <td>Private</td>\n",
       "      <td>154374</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32559</th>\n",
       "      <td>58</td>\n",
       "      <td>Private</td>\n",
       "      <td>151910</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32560</th>\n",
       "      <td>22</td>\n",
       "      <td>Private</td>\n",
       "      <td>201490</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32561</th>\n",
       "      <td>52</td>\n",
       "      <td>Self-emp-inc</td>\n",
       "      <td>287927</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>15024</td>\n",
       "      <td>0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32561 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      age          workclass   fnlwgt    education education-num  \\\n",
       "1      39          State-gov    77516    Bachelors            13   \n",
       "2      50   Self-emp-not-inc    83311    Bachelors            13   \n",
       "3      38            Private   215646      HS-grad             9   \n",
       "4      53            Private   234721         11th             7   \n",
       "5      28            Private   338409    Bachelors            13   \n",
       "...    ..                ...      ...          ...           ...   \n",
       "32557  27            Private   257302   Assoc-acdm            12   \n",
       "32558  40            Private   154374      HS-grad             9   \n",
       "32559  58            Private   151910      HS-grad             9   \n",
       "32560  22            Private   201490      HS-grad             9   \n",
       "32561  52       Self-emp-inc   287927      HS-grad             9   \n",
       "\n",
       "            marital-status          occupation    relationship    race  \\\n",
       "1            Never-married        Adm-clerical   Not-in-family   White   \n",
       "2       Married-civ-spouse     Exec-managerial         Husband   White   \n",
       "3                 Divorced   Handlers-cleaners   Not-in-family   White   \n",
       "4       Married-civ-spouse   Handlers-cleaners         Husband   Black   \n",
       "5       Married-civ-spouse      Prof-specialty            Wife   Black   \n",
       "...                    ...                 ...             ...     ...   \n",
       "32557   Married-civ-spouse        Tech-support            Wife   White   \n",
       "32558   Married-civ-spouse   Machine-op-inspct         Husband   White   \n",
       "32559              Widowed        Adm-clerical       Unmarried   White   \n",
       "32560        Never-married        Adm-clerical       Own-child   White   \n",
       "32561   Married-civ-spouse     Exec-managerial            Wife   White   \n",
       "\n",
       "           sex capital-gain capital-loss  hours-per-week  native-country  \\\n",
       "1         Male         2174            0            40.0   United-States   \n",
       "2         Male            0            0            13.0   United-States   \n",
       "3         Male            0            0            40.0   United-States   \n",
       "4         Male            0            0            40.0   United-States   \n",
       "5       Female            0            0            40.0            Cuba   \n",
       "...        ...          ...          ...             ...             ...   \n",
       "32557   Female            0            0            38.0   United-States   \n",
       "32558     Male            0            0            40.0   United-States   \n",
       "32559   Female            0            0            40.0   United-States   \n",
       "32560     Male            0            0            20.0   United-States   \n",
       "32561   Female        15024            0            40.0   United-States   \n",
       "\n",
       "        class  \n",
       "1       <=50K  \n",
       "2       <=50K  \n",
       "3       <=50K  \n",
       "4       <=50K  \n",
       "5       <=50K  \n",
       "...       ...  \n",
       "32557   <=50K  \n",
       "32558    >50K  \n",
       "32559   <=50K  \n",
       "32560   <=50K  \n",
       "32561    >50K  \n",
       "\n",
       "[32561 rows x 15 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = 'adult.tmls'\n",
    "data = pd.read_csv(filename)\n",
    "# Remove the line with \"r,n,r,n,r,n,n,n,r,r,r,n\"\n",
    "data = data.drop(data.index[0])\n",
    "\n",
    "y_data = data['class']\n",
    "# Replace class names\n",
    "for i, value in enumerate(np.unique(y_data)):\n",
    "    y_data = np.where(y_data == value, i, y_data)\n",
    "y_data = np.asarray(y_data)\n",
    "y_data = y_data.astype(dtype=np.int64)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "94ae1d2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adult Dataset - Multiple runs:\n",
      "[Warning] This takes a while.\n",
      "\n",
      "Accuracy: 0.8482800982800983\n",
      "Accuracy: 0.8527334152334153\n",
      "Accuracy: 0.8493550368550369\n",
      "Accuracy: 0.8490479115479116\n",
      "Accuracy: 0.847512285012285\n"
     ]
    }
   ],
   "source": [
    "print(\"Adult Dataset - Multiple runs:\\n[Warning] This takes a while.\\n\")\n",
    "    \n",
    "for i in range(5):\n",
    "    x_data = data.iloc[:, :-1].values\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        x_data, y_data, test_size=0.2, random_state=None\n",
    "    )\n",
    "\n",
    "    dt = DecisionTree(max_depth=10)\n",
    "    dt.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = dt.predict(X_test)\n",
    "\n",
    "    acc = accuracy(y_test, y_pred)\n",
    "\n",
    "    print(\"Accuracy:\", acc)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
